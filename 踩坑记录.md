# 踩坑记录

## 一、新的TcpConnection对象指针无法加入map

在TcpServer类中，有成员变量 `std::unordered_map<int, TcpConnection::s_ptr> m_connections`，记录所有的TcpConnection对象。在连接断开时，只是把该对象的状态标记为Closed，而不清除该对象。而是由一个间隔1s的定时器事件，负责将以断开的对象清除。

但是，一个连接被断开时，该连接的套接字就可以立刻被操作系统复用，并赋予新的TCP连接，然后将新的TcpConnection对象的指针加入map：

```c++
m_connections.insert({sockfd, connection});
```

但是，此时旧的对象指针可能还没被清除，而 **std::unordered_map::insert 是不能重复插入元素**的，就导致insert失败，新的TcpConnection指针无法加入map，然后在函数结束时就被析构，导致错误发生。因此修改为：

```c++
m_connections[sockfd] = connection;
```



## 二、类成员函数执行到一半，类对象被析构

### 现象

客户端断开连接时，服务器出现Segmentation fault (core dump)

### 查看日志

首先看日志，发现日志为空，说明日志还在内存中没来得及刷盘。因此用gdb打开core文件，定位到合适的栈帧，查看指针指向的内存，可以恢复出没刷盘的日志。发现某个TcpConnection对象在调用了析构函数之后，依旧调用了该对象的成员函数。推测是在类对象析构后，又触发了某事件，通过回调函数执行了该对象的成员函数。

### 查看core栈

用gdb查看core栈，发现段错误是空指针异常导致的，究其原因，是TcpConnection某个指针为空。然后打印该对象的其他成员，例如sockfd，发现都是默认值。这进一步证明了该对象已经被析构。且从core栈中也能看出，是通过std::function回调函数执行到了该成员函数。

### 分析问题

TcpConnection对象只有两种情况被析构：

1. 新的连接到来，使用相同的sockfd，然后替换掉map中旧的智能指针

2. 定时器定时清除已经断开连接的TcpConnection

这两种情况其实都是断开连接才会发生的，因此查看`TcpConnection::close`函数：

```c++
void TcpConnection::close()
{
  m_eventloop->assertInLoopThread();
  assert(m_state == Connected || m_state == HalfClosing);

  // 把定时器全部取消
  clearTimer();
  
  ::close(m_sockfd);
  setState(Closed);
  if (m_close_callback)
    m_close_callback(*this);
  deleteFromEventLoop();

  LOG_DEBUG << "TcpConnection::close(), this = " << this << ", sockfd = " << m_sockfd;
}
```

执行的并发时序可能是这样：

| 时间 |                 TcpConnection::close() 线程                  |                            主线程                            |
| :--: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|  1   |                      ::close(m_sockfd);                      |                                                              |
|  2   |                                                              | 复用sockfd，将新的TcpConnection加入map，析构旧的TcpConnection对象 |
|  3   | m_close_callback(*this);  此时该对象已经被析构，因此是未定义的行为 |                                                              |

因此最终引发了空指针异常。

### 解决问题

由于一旦调用::close()函数，该对象就存在析构的可能，因此在::close()之后不能再用到本对象的任何成员，所以调整`TcpConnection::close()`函数的流程：

```c++
void TcpConnection::close()
{
  m_eventloop->assertInLoopThread();
  assert(m_state == Connected || m_state == HalfClosing);

  // 把定时器全部取消
  clearTimer();
  
  setState(Closed);
  if (m_close_callback)
    m_close_callback(*this);
  deleteFromEventLoop();

  // ::close()必须放在最后
  // 因为close后该fd可能会被其它线程重用
  // 导致 TcpServer的ConnectionMap 中当前对象的智能指针被覆盖，当前对象被析构
  // 所以必须保证::close()后不再使用当前对象的任何资源
  LOG_DEBUG << "TcpConnection::close(), this = " << this << ", sockfd = " << m_sockfd;
  ::close(m_sockfd);
}
```



## 三、服务器响应过慢

### 现象

RPC客户端会有超时的情况

### 定位问题

1. 网络问题

   服务器和客户端都是在本地运行的，不可能真的存在网络超时的问题

2. 客户端自身的问题，例如定时器没正常清理

   经排查，客户端运行正常，定时器都正常清理了

3. Wireshark抓包分析

   抓包分析得知，TCP三次握手正常建立连接后，客户端发送数据，且收到ACK，而服务器始终没有回应。

4. 分析日志

   查看服务器的日志，在连接建立后，没有收到数据

因此初步推测，是连接建立后，服务器没有立刻将该sockfd的可读事件注册到epoll所致。

添加部分调试日志，发现服务器接受新连接后的1～3秒才将sockfd可读事件注册到epoll，这才导致客户端的RPC超时（客户端设置了1秒的超时时间）。

### 继续排查

首先，怀疑是线程花费了大量时间处理其它的事件，尤其是定时器事件。但是查看cpu和内存，发现使用率并不高。随后添加日志，打印了doPending的耗时，发现都是微妙级的，所以可以排除这个因素。

然后从日志中发现了端倪，即连接建立，到epoll_wait返回，竟然间隔了1～3秒，所以断定问题出在这里。epoll_wait设置了如果没有事件发生，则最长等待3秒，但是我添加了wakeup文件描述符，用于提前唤醒。且新连接建立后，用wakeup唤醒，以处理新连接，那么原因可能就是在这里。

```c++
// 向fd中写入一个字节，用于从epoll_wait中返回
  void wakeup()
  {
    if (m_triggered)
      return;
    char buf[8] = {'a'};
    int rt = write(m_fd, buf, 8);
    if (rt != 8) {
      LOG_ERROR << "Write to wakeup fd " << m_fd << " failed, errno = " << errno;
    }
    else {
      // LOG_DEBUG << "Write to wakeup fd " << m_fd << " succeed";
      m_triggered = true;
    }
  }
```

原本想通过 m_triggered 这个变量来避免多个线程重复调用wakeup导致的频繁写入的问题，但可能存在并发问题，导致这个变量没有正常工作，使得wakeup失效。将该变量删除，解决问题。